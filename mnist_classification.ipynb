{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist classification\n",
    "\n",
    "### Exercise objectives\n",
    "- Implement a CNN architecture with convolution layers\n",
    "- Run a Neural Network on images\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "Let's imagine for a moment that you are working for the postal office (and you're in 1970 / 1980). You deal everyday with a enourmous amont of letters, and you want to automate the process of reading the numbers that have been handwritten. This task, called the _Handwriting Recognition_, has been a very complex that has been handled by Bell Labs (among other) where Yann Le Cun used to work, and where such things have been developed : \n",
    "\n",
    "![Number recognition](recognition.gif)\n",
    "\n",
    "\n",
    "The idea is that you have an image (not a video: the animation is here to present what happens with different images) as an input and you try to predict the figure on the image - it corresponds to a classification task, where the output is the class (=figure) the image belongs to, from 0 to 9.\n",
    "\n",
    "This task used to be quite complex back in the time, and still is a benchmark on which a lot of people work. For this reason, the MNIST (for *Modified ou Mixed National Institute of Standards and Technology*) dataset has been created: it corresponds to digit images, from 0 to 9. \n",
    "\n",
    "You goal in this notebook is to build a Convolution Neural Network that can work on such images and predict the corresponding class of each digit image. Keep in mind that this CNN will make you classify hand-written digits, which was a very complex task till the 90's. \n",
    "\n",
    "## The data\n",
    "\n",
    "Keras provides multiple datasets within the Python package. You can load it with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:19.145710Z",
     "start_time": "2021-04-29T07:22:14.174055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 22s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ Let's look at some of the data. \n",
    "\n",
    "Select some of the values of the train set and plot them thanks to the `imshow` function from matplotlib with `cmap` set to `gray`(otherwise, the displayed colors are just some arrangement Matplotlib does, which does not exist in practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:19.731522Z",
     "start_time": "2021-04-29T07:22:19.148711Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x144c003d160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "image_index = 9890 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 9\n",
    "plt.imshow(X_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that neural networks converge faster when the input data are somehow normalized? It goes similarly for input images. \n",
    "\n",
    "❓ Question ❓ As a first preprocessing step, you should normalize your data. For images, it simply implies to divide your input data by the maximal value, i.e. 255. Don't forget to do it on your train and test data.\n",
    "\n",
    "(N.B.: you can also centered your data, by substracting 0.5 but it is not mandatory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.043153Z",
     "start_time": "2021-04-29T07:22:19.734478Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ What is the shape of your images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.050056Z",
     "start_time": "2021-04-29T07:22:20.046331Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('Number of images in x_train', X_train.shape[0])\n",
    "print('Number of images in x_test', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that you have 60.000 training images, all of size (28, 28). However, Keras needs images whose last dimension is the number of channels, which is missing here.\n",
    "\n",
    "❓ Question ❓ Use the `expand_dims` to add one dimension at the end of the training and test data. Then, print the shape of X_train and X_test that should respectively be (60000, 28, 28, 1) and (10000, 28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.063475Z",
     "start_time": "2021-04-29T07:22:20.052948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "print(\"x_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last thing to do to prepare your data is to convert your labels to one-hot encoded categories.\n",
    "\n",
    "❓ Question ❓ Use `to_categorical` to transform your labels. Store the results in `y_train_cat` and `y_test_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.845683Z",
     "start_time": "2021-04-29T07:22:20.840921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valeur 5 est encodée vers le vecteur [0 0 0 0 0 1 0 0 0 0]\n",
      "valeur 4 transformée en vecteur: [0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "y_train_cat  = pd.get_dummies(y_train).values\n",
    "y_test_cat  = pd.get_dummies(y_test).values\n",
    "print(\"La valeur {} est encodée vers le vecteur {}\".format(y_train[0], y_train_cat[0]))\n",
    "print(\"valeur {} transformée en vecteur: {}\".format(y_train[20], y_train_cat[20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are now ready to be used.\n",
    "\n",
    "## The Convolutional Neural Network _aka_ CNN\n",
    "\n",
    "Now, build a Convolutional Neural Network. \n",
    "\n",
    "❓ Question ❓ Based on the course, build a neural network that has:\n",
    "- a `Conv2D` layer with 8 filters, each of size (4, 4), with an input shape suitable for your task, the relu activation function, and padding='same' so as to \n",
    "- a `MaxPool2D` layer with a pool_size of (2, 2)\n",
    "- a second `Conv2D` layer with 16 filters, each of size (3, 3), and the relu activation function\n",
    "- a second `MaxPool2D` layer with a pool_size of (2, 2)\n",
    "- a `Flatten` layer\n",
    "- a first `Dense` layer with 10 neurons and the relu activation function\n",
    "- a last layer that is suited for your task\n",
    "\n",
    "In the function, do not forget to include the compilation of the model, which optimizes the `categorical_crossentropy` with the adam optimizer - and the accuracy should be among the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:24.419923Z",
     "start_time": "2021-04-29T07:22:24.415553Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "    model =Sequential()\n",
    "    ### First convolution & max-pooling\n",
    "    # To complete\n",
    "    model.add(Conv2D(8, (4, 4), activation=\"relu\", padding='Same', input_shape = (28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))),\n",
    "    ### Second convolution & max-pooling\n",
    "    # To complete\n",
    "    model.add(Conv2D(filters =16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    ### Flattening\n",
    "    # To complete\n",
    "    model.add(Flatten())\n",
    "    ### One fully connected\n",
    "    # To completelayers\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    ### Last layer (let's say a classification with 10 output)\n",
    "    # To complete\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    ### Model compilation\n",
    "    # To complete\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ How many trainable parameters are there in your model?\n",
    "- Compute them with `model.summary()` first\n",
    "- Recompute them manually layer per layer then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:47.154385Z",
     "start_time": "2021-04-29T07:22:47.146231Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 8)         136       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5770      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 7,184\n",
      "Trainable params: 7,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ Initialize your model and fit it on the train data. \n",
    "- Do not forget to use a validation set and an early stopping criterion. \n",
    "- Limit at 5 epoch max in this challenge (just to save time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:50.611532Z",
     "start_time": "2021-04-29T07:22:50.608695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.8513WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1688/1688 [==============================] - 33s 20ms/step - loss: 0.4859 - accuracy: 0.8513 - val_loss: 0.1505 - val_accuracy: 0.9587\n",
      "Epoch 2/5\n",
      "1687/1688 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9556WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1688/1688 [==============================] - 33s 20ms/step - loss: 0.1489 - accuracy: 0.9556 - val_loss: 0.1032 - val_accuracy: 0.9693\n",
      "Epoch 3/5\n",
      "1687/1688 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9668WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1091 - accuracy: 0.9668 - val_loss: 0.1021 - val_accuracy: 0.9715\n",
      "Epoch 4/5\n",
      "1687/1688 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 0.9722WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1688/1688 [==============================] - 29s 17ms/step - loss: 0.0907 - accuracy: 0.9722 - val_loss: 0.0867 - val_accuracy: 0.9720\n",
      "Epoch 5/5\n",
      "1685/1688 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9764WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1688/1688 [==============================] - 30s 18ms/step - loss: 0.0781 - accuracy: 0.9764 - val_loss: 0.0751 - val_accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# To complete\n",
    "earlystopping=EarlyStopping(monitor=\"mean_squared_error\", patience=40, verbose=1, mode='auto')\n",
    "epochs = 5\n",
    "output=model.fit(X_train, y_train, epochs=epochs, validation_split=0.1, validation_data=(X_test, y_test), callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably see that the model converges within few epochs. The reason is that there are as many weight update as there are batches within each epoch. For instance, if you batch_size is of 32, you have 60.000/32 = 1875 updates.\n",
    "\n",
    "\n",
    "❓ Question ❓ What is your accuracy on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T15:11:42.884017Z",
     "start_time": "2021-04-27T15:11:42.372506Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0744040310382843\n",
      "Test accuracy: 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should be already impressed by your skills! You solved what was a very hard problem 30 years ago with your CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 Congratulation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
